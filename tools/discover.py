#!/usr/bin/env python3
"""
é£ä¹¦é€šç”¨ç›®å½•ä¾¦å¯Ÿå·¥å…· (Generic Discovery Tool)

åŠŸèƒ½ï¼šé€’å½’å±•å¼€ä¾§è¾¹æ ï¼Œæå–ç›®å½•ç»“æ„ï¼Œæ”¯æŒé€šè¿‡ URL æŒ‡å®šä»»æ„æ–‡æ¡£æ¿å—ã€‚
ç”¨æ³•ï¼špython tools/discover.py --url <URL> [--output <name>]

ä½œè€…: AI Assistant
"""
import asyncio
import json
import logging
import os
import random
import argparse
import sys
from pathlib import Path
from playwright.async_api import async_playwright

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥ä¾¿å¯¼å…¥ core (å¦‚æœéœ€è¦ï¼Œç›®å‰æ˜¯ç‹¬ç«‹çš„)
sys.path.append(str(Path(__file__).parent.parent))

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

async def expand_all_nodes(page):
    """
    é€’å½’å±•å¼€æ‰€æœ‰æŠ˜å èŠ‚ç‚¹
    ç²¾å‡†ç­–ç•¥ï¼šé€šè¿‡ CSS transform å±æ€§åˆ¤æ–­æŠ˜å çŠ¶æ€
    """
    logger.info("å¼€å§‹å±•å¼€æ‰€æœ‰èŠ‚ç‚¹...")
    iteration = 0
    max_retries = 3
    no_change_count = 0
    
    while True:
        iteration += 1
        
        # è·å–æ‰€æœ‰æŠ˜å çš„èŠ‚ç‚¹ç´¢å¼•
        collapsed_indices = await page.evaluate("""
            () => {
                const btns = Array.from(document.querySelectorAll('.ud__expandButton'));
                const collapsedIdx = [];
                btns.forEach((btn, index) => {
                    const icon = btn.querySelector('.ud__expandButton__icon');
                    if (icon) {
                        const style = window.getComputedStyle(icon);
                        if (style.transform && style.transform.includes('matrix(0, -1, 1, 0, 0, 0)')) {
                            collapsedIdx.push(index);
                        }
                    }
                });
                return collapsedIdx;
            }
        """)
        
        if not collapsed_indices:
            no_change_count += 1
            if no_change_count >= max_retries:
                logger.info("æ²¡æœ‰æ›´å¤šæŠ˜å èŠ‚ç‚¹äº†ã€‚")
                break
            logger.info("æœªå‘ç°æŠ˜å èŠ‚ç‚¹ï¼Œç­‰å¾…åé‡è¯•...")
            await page.wait_for_timeout(1000)
            continue
            
        no_change_count = 0
        logger.info(f"ç¬¬ {iteration} è½®ï¼šå‘ç° {len(collapsed_indices)} ä¸ªæŠ˜å èŠ‚ç‚¹ï¼Œæ­£åœ¨å±•å¼€...")
        
        buttons = await page.query_selector_all(".ud__expandButton")
        
        clicked_count = 0
        for idx in collapsed_indices:
            if idx < len(buttons):
                btn = buttons[idx]
                try:
                    if await btn.is_visible():
                        await btn.click()
                        clicked_count += 1
                        await page.wait_for_timeout(random.randint(50, 150))
                except Exception as e:
                    logger.warning(f"ç‚¹å‡»æŒ‰é’®å¤±è´¥ (ç´¢å¼• {idx}): {e}")
        
        if clicked_count == 0:
            logger.info("æ²¡æœ‰å¯ç‚¹å‡»çš„æŒ‰é’®ï¼Œåœæ­¢å±•å¼€ã€‚")
            break
            
        await page.wait_for_timeout(2000)


async def discover(url: str, output_name: str):
    """
    ä¸»ä¾¦å¯Ÿå‡½æ•°
    """
    # ç¡®å®šè¾“å‡ºè·¯å¾„
    base_dir = Path(__file__).parent.parent
    config_dir = base_dir / "configs"
    log_dir = base_dir / "logs"
    
    config_dir.mkdir(exist_ok=True)
    log_dir.mkdir(exist_ok=True)
    
    output_file = config_dir / f"{output_name}_structure.json"
    report_file = log_dir / f"{output_name}_toc_report.md"
    
    logger.info(f"ç›®æ ‡ URL: {url}")
    logger.info(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        )
        page = await context.new_page()

        logger.info(f"æ­£åœ¨å¯¼èˆª...")
        try:
            await page.goto(url, wait_until="domcontentloaded", timeout=60000)
        except Exception as e:
            logger.error(f"å¯¼èˆªå¤±è´¥: {e}")
            await browser.close()
            return
        
        try:
            await page.wait_for_selector(".ud__tree", timeout=20000)
            logger.info("ä¾§è¾¹æ åŠ è½½æˆåŠŸã€‚")
        except Exception:
            logger.error("ä¾§è¾¹æ æœªæ‰¾åˆ°ï¼å¯èƒ½é¡µé¢ç»“æ„ä¸åŒæˆ–åŠ è½½è¶…æ—¶ã€‚")
            await browser.close()
            return

        # é€’å½’å±•å¼€
        await expand_all_nodes(page)
        
        # æå–æœ€ç»ˆç»“æ„
        logger.info("æ­£åœ¨æå–ç›®å½•ç»“æ„...")
        
        nodes = await page.query_selector_all(".ud__tree__node")
        structure = []
        
        for i, node in enumerate(nodes):
            title_el = await node.query_selector(".ud__tree__node__label") 
            title = await title_el.inner_text() if title_el else "Unknown"
            
            # è·å–é“¾æ¥
            try:
                # æ˜¾å¼ä½¿ç”¨ evaluate è·å– hrefï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› null
                node_url = await node.evaluate("node => node.closest('a') ? node.closest('a').href : null")
            except Exception as e:
                logger.warning(f"è·å–é“¾æ¥å¤±è´¥ (node {i}): {e}")
                node_url = None
            
            has_expand = await node.query_selector(".ud__expandButton")
            is_folder = has_expand is not None
            
            # å°è¯•æ¨æ–­å±‚çº§
            level = 0
            try:
                header = await node.query_selector(".ud__tree__node-header") or node
                style = await header.get_attribute("style")
                if style and "padding-left" in style:
                    parts = style.split("padding-left:")
                    if len(parts) > 1:
                        px_val = parts[1].split("px")[0].strip()
                        level = int(float(px_val)) // 20 
            except:
                pass

            node_data = {
                "id": i,
                "title": title.strip(),
                "url": node_url,
                "level": level,
                "is_folder": is_folder,
            }
            structure.append(node_data)
            
        logger.info(f"å…±æ‰¾åˆ° {len(structure)} ä¸ªèŠ‚ç‚¹")
        
        # ä¿å­˜ JSON
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(structure, f, indent=2, ensure_ascii=False)
        logger.info(f"ç»“æ„å·²ä¿å­˜åˆ° {output_file}")
            
        # ç”ŸæˆæŠ¥å‘Š
        with open(report_file, "w", encoding="utf-8") as f:
            f.write(f"# ç›®å½•ç»“æ„æŠ¥å‘Š: {output_name}\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {os.popen('date').read().strip()}\n")
            f.write(f"**æº URL**: {url}\n")
            f.write(f"**æ€»èŠ‚ç‚¹æ•°**: {len(structure)}\n\n")
            f.write("| ID | å±‚çº§ | æ ‡é¢˜ | ç±»å‹ | URL |\n")
            f.write("|---|---|---|---|---|\n")
            for node in structure:
                type_icon = "ğŸ“‚" if node['is_folder'] else "ğŸ“„"
                indent = "&nbsp;&nbsp;" * min(node['level'], 10)
                url_display = node['url'] or '-'
                f.write(f"| {node['id']} | {node['level']} | {indent}{type_icon} {node['title']} | {'æ–‡ä»¶å¤¹' if node['is_folder'] else 'æ–‡æ¡£'} | {url_display} |\n")
        
        logger.info(f"æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
        await browser.close()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="é£ä¹¦é€šç”¨ç›®å½•ä¾¦å¯Ÿå·¥å…·")
    parser.add_argument("--url", type=str, required=True, help="ç›®æ ‡é¡µé¢ URL")
    parser.add_argument("--output", type=str, default="custom", help="è¾“å‡ºæ–‡ä»¶åå‰ç¼€ (é»˜è®¤: custom -> custom_structure.json)")
    
    args = parser.parse_args()
    
    try:
        asyncio.run(discover(args.url, args.output))
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
