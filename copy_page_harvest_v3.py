#!/usr/bin/env python3
"""
é£ä¹¦æ–‡æ¡£å®˜æ–¹ Markdown æŠ“å–å™¨ V3 (æœ€ç»ˆä¼˜åŒ–ç‰ˆ)

åŠŸèƒ½åˆ—è¡¨ï¼š
1. è¿›åº¦æ¡ (tqdm) - æ˜¾ç¤ºå½“å‰è¿›åº¦ã€ETAã€å½“å‰æŠ“å–åç§°
2. æ–­ç‚¹ç»­æŠ“ - è‡ªåŠ¨è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶
3. åè‡ªåŠ¨åŒ–æ£€æµ‹æš‚åœ - é‡åˆ°éªŒè¯é¡µé¢æ—¶æš‚åœå¹¶ç­‰å¾…ç”¨æˆ·æŒ‡ä»¤
4. ç›®å½•åˆ†ç±» - åŸºäº URL è·¯å¾„ç»“æ„åˆ›å»ºæ–‡ä»¶å¤¹
5. çŠ¶æ€æŒä¹…åŒ– - è®°å½•è¿›åº¦åˆ° state.json
6. [V3] ç½‘ç»œè¶…æ—¶é‡è¯• - å•é¡µå¤±è´¥æ—¶è‡ªåŠ¨é‡è¯• 3 æ¬¡
7. [V3] æ—¥å¿—æ–‡ä»¶ - è¾“å‡ºåˆ° harvest.log
8. [V3] Ctrl+C ä¼˜é›…é€€å‡º - ä¿å­˜è¿›åº¦åå†é€€å‡º
9. [V3] æœ€ç»ˆæŠ¥å‘Š - ç”Ÿæˆ Markdown æŠ¥å‘Šï¼ŒåŒ…å«å¼‚å¸¸æ–‡ä»¶åˆ—è¡¨

ä½œè€…: AI Assistant
æœ€åæ›´æ–°: 2026-02-03
"""
import os
import sys
import json
import asyncio
import random
import signal
import time
import logging
from pathlib import Path
from urllib.parse import urlparse
from datetime import datetime

# ç¯å¢ƒæ£€æŸ¥ï¼ˆéµå®ˆå…¨å±€è§„åˆ™ï¼Œè°ƒè¯•æ—¶è·³è¿‡ï¼‰
if os.environ.get('CONDA_DEFAULT_ENV') is None:
    pass

from playwright.async_api import async_playwright

# å°è¯•å¯¼å…¥ tqdm
try:
    from tqdm import tqdm
except ImportError:
    print("[è­¦å‘Š] tqdm æœªå®‰è£…ï¼Œä½¿ç”¨ç®€åŒ–è¿›åº¦æ˜¾ç¤º")
    tqdm = None


# ============ é…ç½® ============
OUTPUT_DIR = Path("docs")
STATE_FILE = Path("harvest_state.json")
LOG_FILE = Path("harvest.log")
REPORT_FILE = Path("harvest_report.md")
ANTI_BOT_KEYWORDS = ["captcha", "challenge", "human verification", "è¯·å®ŒæˆéªŒè¯"]
DELAY_MIN = 1.5
DELAY_MAX = 3.0
MAX_RETRIES = 3  # å•é¡µæœ€å¤§é‡è¯•æ¬¡æ•°
MIN_CONTENT_SIZE = 200  # æœ€å°å†…å®¹å¤§å°é˜ˆå€¼ï¼ˆå­—èŠ‚ï¼‰ï¼Œä½äºæ­¤å€¼è§†ä¸ºå¼‚å¸¸

# ============ æ—¥å¿—è®¾ç½® ============
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE, encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# ============ å…¨å±€ä¸­æ–­æ ‡å¿— ============
shutdown_requested = False


def signal_handler(signum, frame):
    """å¤„ç† Ctrl+C ä¿¡å·ï¼Œå®ç°ä¼˜é›…é€€å‡º"""
    global shutdown_requested
    if shutdown_requested:
        logger.warning("å¼ºåˆ¶é€€å‡º...")
        sys.exit(1)
    logger.warning("\næ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨ä¿å­˜è¿›åº¦å¹¶ä¼˜é›…é€€å‡º...")
    logger.warning("å†æ¬¡æŒ‰ Ctrl+C å¼ºåˆ¶é€€å‡º")
    shutdown_requested = True


# æ³¨å†Œä¿¡å·å¤„ç†å™¨
signal.signal(signal.SIGINT, signal_handler)


class HarvestState:
    """æŠ“å–çŠ¶æ€ç®¡ç†å™¨ - æ”¯æŒæ–­ç‚¹ç»­æŠ“"""
    
    def __init__(self):
        self.completed = set()  # æˆåŠŸçš„ URL
        self.failed = set()     # å¤±è´¥çš„ URL
        self.skipped = set()    # è·³è¿‡çš„ URL
        self.file_sizes = {}    # æ–‡ä»¶å¤§å°è®°å½• {url: size}
        self.paused = False
        self.current_url = None
        self.start_time = None
        self.load()
    
    def load(self):
        """ä»æ–‡ä»¶åŠ è½½çŠ¶æ€"""
        if STATE_FILE.exists():
            try:
                with open(STATE_FILE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.completed = set(data.get('completed', []))
                    self.failed = set(data.get('failed', []))
                    self.skipped = set(data.get('skipped', []))
                    self.file_sizes = data.get('file_sizes', {})
                logger.info(f"å·²åŠ è½½å†å²è¿›åº¦: {len(self.completed)} å®Œæˆ, {len(self.failed)} å¤±è´¥")
            except Exception as e:
                logger.warning(f"æ— æ³•åŠ è½½çŠ¶æ€æ–‡ä»¶: {e}")
    
    def save(self):
        """ä¿å­˜çŠ¶æ€åˆ°æ–‡ä»¶"""
        try:
            with open(STATE_FILE, 'w', encoding='utf-8') as f:
                json.dump({
                    'completed': list(self.completed),
                    'failed': list(self.failed),
                    'skipped': list(self.skipped),
                    'file_sizes': self.file_sizes,
                    'last_updated': datetime.now().isoformat()
                }, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.warning(f"æ— æ³•ä¿å­˜çŠ¶æ€: {e}")
    
    def is_done(self, url):
        return url in self.completed or url in self.skipped
    
    def mark_completed(self, url, file_size=0):
        self.completed.add(url)
        self.file_sizes[url] = file_size
        self.save()
    
    def mark_failed(self, url):
        self.failed.add(url)
        self.save()
    
    def mark_skipped(self, url):
        self.skipped.add(url)
        self.save()


def url_to_folder_path(url: str) -> str:
    """ä» URL æ¨æ–­ç›®å½•è·¯å¾„"""
    try:
        parsed = urlparse(url)
        path_parts = parsed.path.strip('/').split('/')
        if path_parts and path_parts[0] == 'document':
            path_parts = path_parts[1:]
        if len(path_parts) > 1:
            return '/'.join(path_parts[:-1])
        elif len(path_parts) == 1:
            return 'root'
        else:
            return 'uncategorized'
    except:
        return 'uncategorized'


def safe_filename(name: str) -> str:
    """æ¸…ç†æ–‡ä»¶å"""
    illegal_chars = ['/', '\\', ':', '*', '?', '"', '<', '>', '|']
    for char in illegal_chars:
        name = name.replace(char, '_')
    return name[:100]


def detect_anti_bot(page_content: str) -> bool:
    """æ£€æµ‹åè‡ªåŠ¨åŒ–éªŒè¯é¡µé¢"""
    content_lower = page_content.lower()
    for keyword in ANTI_BOT_KEYWORDS:
        if keyword.lower() in content_lower:
            return True
    return False


async def wait_for_user_resume(page):
    """æš‚åœå¹¶ç­‰å¾…ç”¨æˆ·æ¢å¤"""
    print("\n" + "=" * 60)
    print("âš ï¸  æ£€æµ‹åˆ°åè‡ªåŠ¨åŒ–éªŒè¯é¡µé¢ï¼")
    print("è¯·åœ¨æµè§ˆå™¨ä¸­æ‰‹åŠ¨å®ŒæˆéªŒè¯ã€‚")
    print("å®ŒæˆåæŒ‰ Enter ç»§ç»­ï¼Œè¾“å…¥ 'skip' è·³è¿‡ï¼Œè¾“å…¥ 'quit' é€€å‡º")
    print("=" * 60 + "\n")
    
    loop = asyncio.get_event_loop()
    user_input = await loop.run_in_executor(None, input)
    
    if user_input.strip().lower() == 'quit':
        return 'quit'
    elif user_input.strip().lower() == 'skip':
        return 'skip'
    return 'continue'


def generate_report(state: HarvestState, harvest_list: list, elapsed: float):
    """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šï¼ŒåŒ…å«å¼‚å¸¸æ–‡ä»¶åˆ—è¡¨"""
    # æ‰¾å‡ºæ–‡ä»¶å¤§å°å¼‚å¸¸çš„æ¡ç›®
    small_files = []
    for url, size in state.file_sizes.items():
        if size < MIN_CONTENT_SIZE:
            # æ‰¾åˆ°å¯¹åº”çš„ title
            title = "Unknown"
            for node in harvest_list:
                if node.get('url') == url:
                    title = node.get('title', 'Unknown')
                    break
            small_files.append({
                'title': title,
                'url': url,
                'size': size
            })
    
    # æŒ‰å¤§å°æ’åº
    small_files.sort(key=lambda x: x['size'])
    
    report = f"""# é£ä¹¦æ–‡æ¡£æŠ“å–æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**è€—æ—¶**: {elapsed/60:.1f} åˆ†é’Ÿ

## ğŸ“Š ç»Ÿè®¡æ‘˜è¦

| é¡¹ç›® | æ•°é‡ |
|---|---|
| æˆåŠŸ | {len(state.completed)} |
| å¤±è´¥ | {len(state.failed)} |
| è·³è¿‡ | {len(state.skipped)} |

## âš ï¸ æ–‡ä»¶å¤§å°å¼‚å¸¸åˆ—è¡¨ (< {MIN_CONTENT_SIZE} å­—èŠ‚)

ä»¥ä¸‹æ–‡ä»¶å†…å®¹è¿‡å°ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨æ ¸å¯¹ï¼š

| æ ‡é¢˜ | å¤§å° (å­—èŠ‚) | é“¾æ¥ |
|---|---|---|
"""
    
    if small_files:
        for f in small_files:
            report += f"| {f['title']} | {f['size']} | [é“¾æ¥]({f['url']}) |\n"
    else:
        report += "| âœ… æ— å¼‚å¸¸æ–‡ä»¶ | - | - |\n"
    
    # æ·»åŠ å¤±è´¥åˆ—è¡¨
    if state.failed:
        report += "\n## âŒ æŠ“å–å¤±è´¥åˆ—è¡¨\n\n"
        report += "| é“¾æ¥ |\n|---|\n"
        for url in state.failed:
            # æ‰¾åˆ°å¯¹åº”çš„ title
            title = "Unknown"
            for node in harvest_list:
                if node.get('url') == url:
                    title = node.get('title', 'Unknown')
                    break
            report += f"| [{title}]({url}) |\n"
    
    # å†™å…¥æŠ¥å‘Šæ–‡ä»¶
    with open(REPORT_FILE, 'w', encoding='utf-8') as f:
        f.write(report)
    
    logger.info(f"æŠ¥å‘Šå·²ç”Ÿæˆ: {REPORT_FILE}")
    return report


async def copy_page_harvest_v3(limit: int = 0):
    """
    æœ€ç»ˆä¼˜åŒ–ç‰ˆæŠ“å–ä¸»å‡½æ•°
    """
    global shutdown_requested
    
    state = HarvestState()
    state.start_time = time.time()
    
    # 1. åŠ è½½ç›®å½•ç»“æ„
    structure_path = Path("structure.json")
    if not structure_path.exists():
        logger.error(f"{structure_path} ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ discover_tree.py")
        return

    with open(structure_path, 'r', encoding='utf-8') as f:
        nodes = json.load(f)

    # è¿‡æ»¤æ‰æ²¡æœ‰ URL çš„ç›®å½•èŠ‚ç‚¹
    harvest_list = [n for n in nodes if n.get('url') and n['url'].startswith('http')]
    
    # è¿‡æ»¤å·²å®Œæˆçš„
    pending_list = [n for n in harvest_list if not state.is_done(n.get('url'))]
    
    if limit > 0:
        pending_list = pending_list[:limit]
        logger.info(f"[æ¨¡å¼] é™åˆ¶æŠ“å– {limit} é¡µ")
    
    total = len(harvest_list)
    pending = len(pending_list)
    done = len(state.completed)
    
    print(f"\n{'=' * 50}")
    print(f"ğŸ“Š æŠ“å–ç»Ÿè®¡")
    print(f"   æ€»é¡µé¢: {total}")
    print(f"   å·²å®Œæˆ: {done}")
    print(f"   å¾…æŠ“å–: {pending}")
    print(f"{'=' * 50}\n")
    
    if pending == 0:
        logger.info("âœ… æ‰€æœ‰é¡µé¢å·²æŠ“å–å®Œæˆï¼")
        generate_report(state, harvest_list, time.time() - state.start_time)
        return
    
    OUTPUT_DIR.mkdir(exist_ok=True)

    # 2. å¯åŠ¨ Playwright
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        context = await browser.new_context()
        await context.grant_permissions(['clipboard-read', 'clipboard-write'])
        page = await context.new_page()
        
        success_count = 0
        fail_count = 0
        skip_count = 0
        
        if tqdm:
            progress = tqdm(pending_list, desc="æŠ“å–è¿›åº¦", unit="é¡µ")
        else:
            progress = pending_list
        
        for i, node in enumerate(progress):
            # æ£€æŸ¥æ˜¯å¦æ”¶åˆ°ä¸­æ–­ä¿¡å·
            if shutdown_requested:
                logger.warning("æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œä¿å­˜è¿›åº¦å¹¶é€€å‡º...")
                break
            
            title = node.get('title', 'Unknown')
            url = node.get('url')
            node_id = node.get('id', i)
            
            if tqdm:
                progress.set_postfix_str(f"å½“å‰: {title[:25]}...")
            else:
                elapsed = time.time() - state.start_time
                eta = (elapsed / (i + 1)) * (pending - i - 1) if i > 0 else 0
                print(f"[{i+1}/{pending}] {title} (ETA: {eta/60:.1f}åˆ†é’Ÿ)")
            
            folder_path = url_to_folder_path(url)
            output_folder = OUTPUT_DIR / folder_path
            output_folder.mkdir(parents=True, exist_ok=True)
            
            safe_title = safe_filename(title)
            output_file = output_folder / f"{node_id:04d}_{safe_title}.md"
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            if output_file.exists() and output_file.stat().st_size > 100:
                if tqdm:
                    progress.write(f"  â­ï¸  è·³è¿‡: {title} (æ–‡ä»¶å·²å­˜åœ¨)")
                skip_count += 1
                state.mark_skipped(url)
                continue
            
            # ====== å¸¦é‡è¯•çš„æŠ“å–é€»è¾‘ ======
            success = False
            last_error = None
            
            for retry in range(MAX_RETRIES):
                if shutdown_requested:
                    break
                    
                try:
                    await page.goto(url, wait_until="networkidle", timeout=30000)
                    
                    # æ£€æŸ¥åè‡ªåŠ¨åŒ–
                    page_content = await page.content()
                    if detect_anti_bot(page_content):
                        action = await wait_for_user_resume(page)
                        if action == 'quit':
                            shutdown_requested = True
                            break
                        elif action == 'skip':
                            state.mark_skipped(url)
                            skip_count += 1
                            success = True  # æ ‡è®°ä¸ºå·²å¤„ç†
                            break
                    
                    # ç­‰å¾…æ­£æ–‡åŠ è½½
                    try:
                        await page.wait_for_selector(".doc-content", timeout=10000)
                    except:
                        pass
                    
                    await asyncio.sleep(1)
                    
                    # ç‚¹å‡»"å¤åˆ¶é¡µé¢"æŒ‰é’®
                    copy_btn = page.locator('button:has-text("å¤åˆ¶é¡µé¢")')
                    
                    if await copy_btn.count() > 0:
                        await copy_btn.first.click()
                        await asyncio.sleep(0.5)
                        
                        clipboard_content = await page.evaluate("navigator.clipboard.readText()")
                        
                        if clipboard_content and len(clipboard_content) > 50:
                            content_to_write = f"# {title}\n\n> Source: {url}\n\n---\n\n{clipboard_content}"
                            with open(output_file, 'w', encoding='utf-8') as f:
                                f.write(content_to_write)
                            
                            file_size = len(content_to_write)
                            if tqdm:
                                # å°æ–‡ä»¶è­¦å‘Š
                                if file_size < MIN_CONTENT_SIZE:
                                    progress.write(f"  âš ï¸  {title} ({file_size} å­—èŠ‚ - å†…å®¹è¿‡å°)")
                                else:
                                    progress.write(f"  âœ… {title} ({file_size} å­—èŠ‚)")
                            
                            success_count += 1
                            state.mark_completed(url, file_size)
                            success = True
                            break
                        else:
                            last_error = "å‰ªè´´æ¿å†…å®¹ä¸ºç©º"
                            if retry < MAX_RETRIES - 1:
                                logger.warning(f"  é‡è¯• {retry+1}/{MAX_RETRIES}: {title} - {last_error}")
                                await asyncio.sleep(2)
                    else:
                        # Fallback
                        await page.locator(".doc-content").click()
                        await page.keyboard.press("Control+a")
                        await page.keyboard.press("Control+c")
                        await asyncio.sleep(0.5)
                        
                        clipboard_content = await page.evaluate("navigator.clipboard.readText()")
                        
                        if clipboard_content and len(clipboard_content) > 50:
                            content_to_write = f"# {title}\n\n> Source: {url}\n\n---\n\n{clipboard_content}"
                            with open(output_file, 'w', encoding='utf-8') as f:
                                f.write(content_to_write)
                            file_size = len(content_to_write)
                            success_count += 1
                            state.mark_completed(url, file_size)
                            success = True
                            break
                        else:
                            last_error = "å¤‡ç”¨æ–¹æ¡ˆä¹Ÿå¤±è´¥"
                            
                except Exception as e:
                    last_error = str(e)[:80]
                    if retry < MAX_RETRIES - 1:
                        logger.warning(f"  é‡è¯• {retry+1}/{MAX_RETRIES}: {title} - {last_error}")
                        await asyncio.sleep(2)
            
            if not success and not shutdown_requested:
                if tqdm:
                    progress.write(f"  âŒ {title} (å¤±è´¥: {last_error})")
                logger.error(f"æŠ“å–å¤±è´¥: {title} - {last_error}")
                fail_count += 1
                state.mark_failed(url)
            
            # éšæœºå»¶è¿Ÿ
            if not shutdown_requested:
                await asyncio.sleep(random.uniform(DELAY_MIN, DELAY_MAX))
        
        await browser.close()
    
    # æœ€ç»ˆæŠ¥å‘Š
    elapsed = time.time() - state.start_time
    print(f"\n{'=' * 50}")
    print(f"ğŸ“Š æŠ“å–å®ŒæˆæŠ¥å‘Š")
    print(f"   è€—æ—¶: {elapsed/60:.1f} åˆ†é’Ÿ")
    print(f"   æˆåŠŸ: {success_count}")
    print(f"   å¤±è´¥: {fail_count}")
    print(f"   è·³è¿‡: {skip_count}")
    print(f"   æ€»å®Œæˆ: {len(state.completed)}/{total}")
    print(f"{'=' * 50}")
    
    # ç”Ÿæˆ Markdown æŠ¥å‘Š
    generate_report(state, harvest_list, elapsed)


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="é£ä¹¦æ–‡æ¡£æŠ“å–å™¨ V3 (æœ€ç»ˆä¼˜åŒ–ç‰ˆ)")
    parser.add_argument("--limit", type=int, default=0, help="é™åˆ¶æŠ“å–é¡µé¢æ•° (0=å…¨é‡)")
    args = parser.parse_args()
    
    asyncio.run(copy_page_harvest_v3(limit=args.limit))
