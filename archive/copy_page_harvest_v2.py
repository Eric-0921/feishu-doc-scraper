#!/usr/bin/env python3
"""
é£ä¹¦æ–‡æ¡£å®˜æ–¹ Markdown æŠ“å–å™¨ V2 (å¢å¼ºç‰ˆ)

æ–°å¢åŠŸèƒ½ï¼š
1. è¿›åº¦æ¡ (tqdm) - æ˜¾ç¤ºå½“å‰è¿›åº¦ã€ETAã€å½“å‰æŠ“å–åç§°
2. æ–­ç‚¹ç»­æŠ“ - è‡ªåŠ¨è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶
3. åè‡ªåŠ¨åŒ–æ£€æµ‹æš‚åœ - é‡åˆ°éªŒè¯é¡µé¢æ—¶æš‚åœå¹¶ç­‰å¾…ç”¨æˆ·æŒ‡ä»¤
4. ç›®å½•åˆ†ç±» - åŸºäº URL è·¯å¾„ç»“æ„åˆ›å»ºæ–‡ä»¶å¤¹
5. çŠ¶æ€æŒä¹…åŒ– - è®°å½•è¿›åº¦åˆ° state.json

ä½œè€…: AI Assistant
æœ€åæ›´æ–°: 2026-02-03
"""
import os
import sys
import json
import asyncio
import random
import signal
import time
from pathlib import Path
from urllib.parse import urlparse
from datetime import datetime

# ç¯å¢ƒæ£€æŸ¥ï¼ˆéµå®ˆå…¨å±€è§„åˆ™ï¼Œè°ƒè¯•æ—¶è·³è¿‡ï¼‰
if os.environ.get('CONDA_DEFAULT_ENV') is None:
    pass

from playwright.async_api import async_playwright

# å°è¯•å¯¼å…¥ tqdmï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ç®€å•çš„æ›¿ä»£
try:
    from tqdm import tqdm
except ImportError:
    print("[è­¦å‘Š] tqdm æœªå®‰è£…ï¼Œä½¿ç”¨ç®€åŒ–è¿›åº¦æ˜¾ç¤º")
    tqdm = None


# ============ é…ç½® ============
OUTPUT_DIR = Path("docs")
STATE_FILE = Path("harvest_state.json")
# ç§»é™¤ "æœºå™¨äºº" å› ä¸ºæ­£å¸¸æ–‡æ¡£å†…å®¹ä¸­ä¼šå‡ºç°è¯¥è¯
ANTI_BOT_KEYWORDS = ["captcha", "challenge", "human verification", "è¯·å®ŒæˆéªŒè¯"]
DELAY_MIN = 1.5
DELAY_MAX = 3.0


class HarvestState:
    """æŠ“å–çŠ¶æ€ç®¡ç†å™¨ - æ”¯æŒæ–­ç‚¹ç»­æŠ“"""
    
    def __init__(self):
        self.completed = set()
        self.failed = set()
        self.skipped = set()
        self.paused = False
        self.current_url = None
        self.start_time = None
        self.load()
    
    def load(self):
        """ä»æ–‡ä»¶åŠ è½½çŠ¶æ€"""
        if STATE_FILE.exists():
            try:
                with open(STATE_FILE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.completed = set(data.get('completed', []))
                    self.failed = set(data.get('failed', []))
                    self.skipped = set(data.get('skipped', []))
                print(f"[çŠ¶æ€] å·²åŠ è½½å†å²è¿›åº¦: {len(self.completed)} å®Œæˆ, {len(self.failed)} å¤±è´¥")
            except Exception as e:
                print(f"[è­¦å‘Š] æ— æ³•åŠ è½½çŠ¶æ€æ–‡ä»¶: {e}")
    
    def save(self):
        """ä¿å­˜çŠ¶æ€åˆ°æ–‡ä»¶"""
        try:
            with open(STATE_FILE, 'w', encoding='utf-8') as f:
                json.dump({
                    'completed': list(self.completed),
                    'failed': list(self.failed),
                    'skipped': list(self.skipped),
                    'last_updated': datetime.now().isoformat()
                }, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"[è­¦å‘Š] æ— æ³•ä¿å­˜çŠ¶æ€: {e}")
    
    def is_done(self, url):
        """æ£€æŸ¥ URL æ˜¯å¦å·²å®Œæˆ"""
        return url in self.completed or url in self.skipped
    
    def mark_completed(self, url):
        self.completed.add(url)
        self.save()
    
    def mark_failed(self, url):
        self.failed.add(url)
        self.save()
    
    def mark_skipped(self, url):
        self.skipped.add(url)
        self.save()


def url_to_folder_path(url: str) -> str:
    """
    ä» URL æ¨æ–­ç›®å½•è·¯å¾„
    
    ä¾‹å¦‚:
    https://open.feishu.cn/document/client-docs/bot-v3/add-custom-bot
    -> client-docs/bot-v3
    """
    try:
        parsed = urlparse(url)
        path_parts = parsed.path.strip('/').split('/')
        
        # ç§»é™¤ 'document' å‰ç¼€å’Œæœ€åçš„æ–‡ä»¶å
        if path_parts and path_parts[0] == 'document':
            path_parts = path_parts[1:]
        
        if len(path_parts) > 1:
            # å–é™¤æœ€åä¸€é¡¹ï¼ˆæ–‡æ¡£åï¼‰å¤–çš„æ‰€æœ‰è·¯å¾„
            folder_parts = path_parts[:-1]
            return '/'.join(folder_parts)
        elif len(path_parts) == 1:
            return 'root'
        else:
            return 'uncategorized'
    except:
        return 'uncategorized'


def safe_filename(name: str) -> str:
    """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤éæ³•å­—ç¬¦"""
    illegal_chars = ['/', '\\', ':', '*', '?', '"', '<', '>', '|']
    for char in illegal_chars:
        name = name.replace(char, '_')
    return name[:100]  # é™åˆ¶é•¿åº¦


def detect_anti_bot(page_content: str) -> bool:
    """æ£€æµ‹åè‡ªåŠ¨åŒ–éªŒè¯é¡µé¢"""
    content_lower = page_content.lower()
    for keyword in ANTI_BOT_KEYWORDS:
        if keyword.lower() in content_lower:
            return True
    return False


async def wait_for_user_resume(page):
    """
    æš‚åœå¹¶ç­‰å¾…ç”¨æˆ·æ¢å¤
    ç”¨æˆ·éœ€è¦æ‰‹åŠ¨å®ŒæˆéªŒè¯ï¼Œç„¶åæŒ‰å›è½¦ç»§ç»­
    """
    print("\n" + "=" * 60)
    print("âš ï¸  æ£€æµ‹åˆ°åè‡ªåŠ¨åŒ–éªŒè¯é¡µé¢ï¼")
    print("è¯·åœ¨æµè§ˆå™¨ä¸­æ‰‹åŠ¨å®ŒæˆéªŒè¯ã€‚")
    print("å®Œæˆåï¼Œè¯·æŒ‰ Enter é”®ç»§ç»­...")
    print("è¾“å…¥ 'skip' è·³è¿‡å½“å‰é¡µé¢ï¼Œè¾“å…¥ 'quit' é€€å‡ºç¨‹åº")
    print("=" * 60 + "\n")
    
    # éé˜»å¡ç­‰å¾…ç”¨æˆ·è¾“å…¥
    loop = asyncio.get_event_loop()
    user_input = await loop.run_in_executor(None, input)
    
    if user_input.strip().lower() == 'quit':
        return 'quit'
    elif user_input.strip().lower() == 'skip':
        return 'skip'
    return 'continue'


async def copy_page_harvest_v2(limit: int = 0):
    """
    å¢å¼ºç‰ˆæŠ“å–ä¸»å‡½æ•°
    
    Args:
        limit: é¡µé¢æ•°é‡é™åˆ¶ (0 = å…¨é‡æŠ“å–)
    """
    state = HarvestState()
    state.start_time = time.time()
    
    # 1. åŠ è½½ç›®å½•ç»“æ„
    structure_path = Path("structure.json")
    if not structure_path.exists():
        print(f"[é”™è¯¯] {structure_path} ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ discover_tree.py")
        return

    with open(structure_path, 'r', encoding='utf-8') as f:
        nodes = json.load(f)

    # è¿‡æ»¤æ‰æ²¡æœ‰ URL çš„ç›®å½•èŠ‚ç‚¹
    harvest_list = [n for n in nodes if n.get('url') and n['url'].startswith('http')]
    
    # è¿‡æ»¤å·²å®Œæˆçš„
    pending_list = [n for n in harvest_list if not state.is_done(n.get('url'))]
    
    if limit > 0:
        pending_list = pending_list[:limit]
        print(f"[æ¨¡å¼] é™åˆ¶æŠ“å– {limit} é¡µ")
    
    total = len(harvest_list)
    pending = len(pending_list)
    done = len(state.completed)
    
    print(f"\n{'=' * 50}")
    print(f"ğŸ“Š æŠ“å–ç»Ÿè®¡")
    print(f"   æ€»é¡µé¢: {total}")
    print(f"   å·²å®Œæˆ: {done}")
    print(f"   å¾…æŠ“å–: {pending}")
    print(f"{'=' * 50}\n")
    
    if pending == 0:
        print("âœ… æ‰€æœ‰é¡µé¢å·²æŠ“å–å®Œæˆï¼")
        return
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    OUTPUT_DIR.mkdir(exist_ok=True)

    # 2. å¯åŠ¨ Playwright
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)  # éæ— å¤´æ¨¡å¼
        context = await browser.new_context()
        
        # è‡ªåŠ¨æˆæƒå‰ªè´´æ¿æƒé™ (è§£å†³é¦–æ¬¡å¼¹çª—é—®é¢˜)
        await context.grant_permissions(['clipboard-read', 'clipboard-write'])
        
        page = await context.new_page()
        
        success_count = 0
        fail_count = 0
        skip_count = 0
        
        # ä½¿ç”¨ tqdm æˆ–ç®€åŒ–è¿›åº¦
        if tqdm:
            progress = tqdm(pending_list, desc="æŠ“å–è¿›åº¦", unit="é¡µ")
        else:
            progress = pending_list
        
        for i, node in enumerate(progress):
            title = node.get('title', 'Unknown')
            url = node.get('url')
            
            # æ›´æ–°è¿›åº¦æ¡æè¿°
            if tqdm:
                progress.set_postfix_str(f"å½“å‰: {title[:30]}...")
            else:
                elapsed = time.time() - state.start_time
                eta = (elapsed / (i + 1)) * (pending - i - 1) if i > 0 else 0
                print(f"[{i+1}/{pending}] {title} (ETA: {eta/60:.1f}åˆ†é’Ÿ)")
            
            # åŸºäº URL åˆ›å»ºç›®å½•
            folder_path = url_to_folder_path(url)
            output_folder = OUTPUT_DIR / folder_path
            output_folder.mkdir(parents=True, exist_ok=True)
            
            safe_title = safe_filename(title)
            # ä½¿ç”¨ structure.json ä¸­çš„ id ä½œä¸ºå…¨å±€åºå· (4ä½æ•°å­—å‰ç¼€)
            node_id = node.get('id', i)
            output_file = output_folder / f"{node_id:04d}_{safe_title}.md"
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆäºŒçº§æ–­ç‚¹ï¼‰
            if output_file.exists() and output_file.stat().st_size > 100:
                if tqdm:
                    progress.write(f"  â­ï¸  è·³è¿‡: {title} (æ–‡ä»¶å·²å­˜åœ¨)")
                skip_count += 1
                state.mark_skipped(url)
                continue
            
            try:
                # æ‰“å¼€é¡µé¢
                await page.goto(url, wait_until="networkidle", timeout=30000)
                
                # æ£€æŸ¥åè‡ªåŠ¨åŒ–
                page_content = await page.content()
                if detect_anti_bot(page_content):
                    action = await wait_for_user_resume(page)
                    if action == 'quit':
                        print("\n[ç”¨æˆ·ä¸­æ–­] ä¿å­˜çŠ¶æ€å¹¶é€€å‡º...")
                        break
                    elif action == 'skip':
                        state.mark_skipped(url)
                        skip_count += 1
                        continue
                
                # ç­‰å¾…æ­£æ–‡åŠ è½½
                try:
                    await page.wait_for_selector(".doc-content", timeout=10000)
                except:
                    pass
                
                await asyncio.sleep(1)
                
                # ç‚¹å‡»"å¤åˆ¶é¡µé¢"æŒ‰é’®
                copy_btn = page.locator('button:has-text("å¤åˆ¶é¡µé¢")')
                
                if await copy_btn.count() > 0:
                    await copy_btn.first.click()
                    await asyncio.sleep(0.5)
                    
                    # è¯»å–å‰ªè´´æ¿
                    clipboard_content = await page.evaluate("navigator.clipboard.readText()")
                    
                    if clipboard_content and len(clipboard_content) > 50:
                        with open(output_file, 'w', encoding='utf-8') as f:
                            f.write(f"# {title}\n\n")
                            f.write(f"> Source: {url}\n\n---\n\n")
                            f.write(clipboard_content)
                        
                        if tqdm:
                            progress.write(f"  âœ… {title} ({len(clipboard_content)} å­—ç¬¦)")
                        success_count += 1
                        state.mark_completed(url)
                    else:
                        if tqdm:
                            progress.write(f"  âŒ {title} (å‰ªè´´æ¿å†…å®¹ä¸ºç©º)")
                        fail_count += 1
                        state.mark_failed(url)
                else:
                    # Fallback: é€‰ä¸­æ­£æ–‡å¹¶å¤åˆ¶
                    if tqdm:
                        progress.write(f"  âš ï¸  {title} (æ— å¤åˆ¶æŒ‰é’®ï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ)")
                    await page.locator(".doc-content").click()
                    await page.keyboard.press("Control+a")
                    await page.keyboard.press("Control+c")
                    await asyncio.sleep(0.5)
                    
                    clipboard_content = await page.evaluate("navigator.clipboard.readText()")
                    
                    if clipboard_content and len(clipboard_content) > 50:
                        with open(output_file, 'w', encoding='utf-8') as f:
                            f.write(f"# {title}\n\n")
                            f.write(f"> Source: {url}\n\n---\n\n")
                            f.write(clipboard_content)
                        success_count += 1
                        state.mark_completed(url)
                    else:
                        fail_count += 1
                        state.mark_failed(url)
                
            except Exception as e:
                if tqdm:
                    progress.write(f"  âŒ {title} é”™è¯¯: {str(e)[:50]}")
                else:
                    print(f"  âŒ é”™è¯¯: {e}")
                fail_count += 1
                state.mark_failed(url)
            
            # éšæœºå»¶è¿Ÿï¼ˆåçˆ¬ï¼‰
            await asyncio.sleep(random.uniform(DELAY_MIN, DELAY_MAX))
        
        await browser.close()
    
    # æœ€ç»ˆæŠ¥å‘Š
    elapsed = time.time() - state.start_time
    print(f"\n{'=' * 50}")
    print(f"ğŸ“Š æŠ“å–å®ŒæˆæŠ¥å‘Š")
    print(f"   è€—æ—¶: {elapsed/60:.1f} åˆ†é’Ÿ")
    print(f"   æˆåŠŸ: {success_count}")
    print(f"   å¤±è´¥: {fail_count}")
    print(f"   è·³è¿‡: {skip_count}")
    print(f"   æ€»å®Œæˆ: {len(state.completed)}/{total}")
    print(f"{'=' * 50}")


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="é£ä¹¦æ–‡æ¡£æŠ“å–å™¨ V2")
    parser.add_argument("--limit", type=int, default=0, help="é™åˆ¶æŠ“å–é¡µé¢æ•° (0=å…¨é‡)")
    args = parser.parse_args()
    
    asyncio.run(copy_page_harvest_v2(limit=args.limit))
